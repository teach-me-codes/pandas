{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Introduction to Pandas This tutorial guide you to fundamentals of Pandas for DataFrame, indexing, subframing, meging, concatation, plotting, lambda transformation etc.","title":"Home"},{"location":"#introduction-to-pandas","text":"This tutorial guide you to fundamentals of Pandas for DataFrame, indexing, subframing, meging, concatation, plotting, lambda transformation etc.","title":"Introduction to Pandas"},{"location":"pandas/","text":"Introduction to Pandas Course Track: DataFrame Indexing Data Exploration GroupBy Lambda Transformation","title":"Introduction"},{"location":"pandas/#introduction-to-pandas","text":"Course Track: DataFrame Indexing Data Exploration GroupBy Lambda Transformation","title":"Introduction to Pandas"},{"location":"CreateDF/createdf/","text":"DataFrame Creation In this notebook, we will learn to create new DataFrame object from other data structures( e.g.,numpy array and dictionary) and convert data frame to numpy array and dictionary. The defult setting for pandas DataFrame is pandas.DataFrame(data=None, index=None, columns=None, dtype=None, copy=False) import pandas as pd import numpy as np import seaborn as sns import matplotlib.pyplot as plt % matplotlib inline sns . set() 1. To create new DataFrame from Numpy array. Let's create a random array of size(100,20) and random column names. We will use these array and column names to create the DataFrame in next step. import random as random A = np . random . rand( 100 , 10 ) letter = [ 'A' , 'B' , 'C' , 'D' , 'E' , 'F' , 'G' , 'H' , 'X' ] def namer (n): col_names = [ random . choice(letter)\\ + random . choice(letter)\\ + random . choice(letter)\\ + random . choice(letter) for i in range (n)] return col_names print (namer(A . shape[ 1 ])) ['HHEE', 'FEGD', 'BFHC', 'HXFC', 'CBDF', 'DEDH', 'CBCX', 'XGXB', 'GCBC', 'FDEE'] df = pd . DataFrame(A, columns = col_names ) df . head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } AAGF XBGA DXAC XEDB EDCG ABDH GFHX FAAB BBEC DGDC 0 0.285058 0.456733 0.841292 0.397957 0.888982 0.970782 0.379687 0.565177 0.657939 0.461385 1 0.725005 0.432756 0.037801 0.020203 0.590901 0.590571 0.623529 0.166581 0.179392 0.454290 2 0.668743 0.352332 0.642905 0.427461 0.025124 0.365414 0.609983 0.568686 0.522738 0.525048 3 0.807165 0.827478 0.542088 0.628743 0.616745 0.386370 0.632225 0.387794 0.618686 0.786503 4 0.645945 0.136078 0.769546 0.721885 0.107891 0.128859 0.938451 0.875492 0.647702 0.148635 To save data from new DataFrame to a file: df . to_csv( 'data/test.csv' ) 2. To create new DataFrame from list of dictionaries. Here we will create a list with collection of dictionaries. Each of the dictionary will have keys and values. Using this list of dictionaries, we will create another DataFrame . The keys of the dictionary will serve as the column names. LD = [] for i in range ( 100 ): LD . append({ 'Player' : namer( 1 )[ 0 ],\\ 'game1' : random . uniform( 0 , 1 ),\\ 'game2' : random . uniform( 0 , 1 ),\\ 'game3' : random . uniform( 0 , 1 ), 'game4' : random . uniform( 0 , 1 ), 'game5' : random . uniform( 0 , 1 )}) LD[ 0 ] {'Player': 'BGXB', 'game1': 0.2965944756471328, 'game2': 0.11334763879800447, 'game3': 0.028543866127768824, 'game4': 0.225405432495144, 'game5': 0.05423542200055986} DF = pd . DataFrame(LD) DF = DF . set_index( \"Player\" ) DF . head( 10 ) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } game1 game2 game3 game4 game5 Player BGXB 0.296594 0.113348 0.028544 0.225405 0.054235 DBDB 0.047226 0.107065 0.801571 0.816877 0.556934 AXXH 0.862611 0.439051 0.083341 0.389785 0.258748 BXED 0.643533 0.082176 0.167241 0.405304 0.088063 FXGE 0.279076 0.000998 0.949414 0.303408 0.009342 AHDC 0.617194 0.272401 0.252663 0.788798 0.130996 CXGA 0.104552 0.895106 0.414877 0.167643 0.454175 BDBA 0.045650 0.926742 0.454097 0.055006 0.939082 HBDC 0.069192 0.797224 0.943648 0.567334 0.044285 EBBX 0.383365 0.852788 0.679330 0.418570 0.817291 3. To create DataFrame from a List : A = [random . uniform( 0 , 1 ) for i in range ( 10 )] B = [random . uniform( 0 , 1 ) for i in range ( 10 )] C = [random . uniform( 0 , 1 ) for i in range ( 10 )] D = [random . uniform( 0 , 1 ) for i in range ( 10 )] df = pd . DataFrame() df[ 'A' ],df[ 'B' ],df[ 'C' ],df[ 'D' ] = A,B,C,D df . head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } A B C D 0 0.816389 0.212530 0.705185 0.225743 1 0.646496 0.876869 0.648350 0.788687 2 0.869173 0.832004 0.516009 0.917783 3 0.668866 0.778850 0.834528 0.243842 4 0.742311 0.984313 0.872512 0.451476 References: Pydata document for Styling DataFrame visualization","title":"Createdf"},{"location":"CreateDF/createdf/#dataframe-creation","text":"In this notebook, we will learn to create new DataFrame object from other data structures( e.g.,numpy array and dictionary) and convert data frame to numpy array and dictionary. The defult setting for pandas DataFrame is pandas.DataFrame(data=None, index=None, columns=None, dtype=None, copy=False) import pandas as pd import numpy as np import seaborn as sns import matplotlib.pyplot as plt % matplotlib inline sns . set()","title":"DataFrame Creation"},{"location":"CreateDF/createdf/#1-to-create-new-dataframe-from-numpy-array","text":"Let's create a random array of size(100,20) and random column names. We will use these array and column names to create the DataFrame in next step. import random as random A = np . random . rand( 100 , 10 ) letter = [ 'A' , 'B' , 'C' , 'D' , 'E' , 'F' , 'G' , 'H' , 'X' ] def namer (n): col_names = [ random . choice(letter)\\ + random . choice(letter)\\ + random . choice(letter)\\ + random . choice(letter) for i in range (n)] return col_names print (namer(A . shape[ 1 ])) ['HHEE', 'FEGD', 'BFHC', 'HXFC', 'CBDF', 'DEDH', 'CBCX', 'XGXB', 'GCBC', 'FDEE'] df = pd . DataFrame(A, columns = col_names ) df . head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } AAGF XBGA DXAC XEDB EDCG ABDH GFHX FAAB BBEC DGDC 0 0.285058 0.456733 0.841292 0.397957 0.888982 0.970782 0.379687 0.565177 0.657939 0.461385 1 0.725005 0.432756 0.037801 0.020203 0.590901 0.590571 0.623529 0.166581 0.179392 0.454290 2 0.668743 0.352332 0.642905 0.427461 0.025124 0.365414 0.609983 0.568686 0.522738 0.525048 3 0.807165 0.827478 0.542088 0.628743 0.616745 0.386370 0.632225 0.387794 0.618686 0.786503 4 0.645945 0.136078 0.769546 0.721885 0.107891 0.128859 0.938451 0.875492 0.647702 0.148635 To save data from new DataFrame to a file: df . to_csv( 'data/test.csv' )","title":"1. To create new DataFrame from Numpy array."},{"location":"CreateDF/createdf/#2-to-create-new-dataframe-from-list-of-dictionaries","text":"Here we will create a list with collection of dictionaries. Each of the dictionary will have keys and values. Using this list of dictionaries, we will create another DataFrame . The keys of the dictionary will serve as the column names. LD = [] for i in range ( 100 ): LD . append({ 'Player' : namer( 1 )[ 0 ],\\ 'game1' : random . uniform( 0 , 1 ),\\ 'game2' : random . uniform( 0 , 1 ),\\ 'game3' : random . uniform( 0 , 1 ), 'game4' : random . uniform( 0 , 1 ), 'game5' : random . uniform( 0 , 1 )}) LD[ 0 ] {'Player': 'BGXB', 'game1': 0.2965944756471328, 'game2': 0.11334763879800447, 'game3': 0.028543866127768824, 'game4': 0.225405432495144, 'game5': 0.05423542200055986} DF = pd . DataFrame(LD) DF = DF . set_index( \"Player\" ) DF . head( 10 ) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } game1 game2 game3 game4 game5 Player BGXB 0.296594 0.113348 0.028544 0.225405 0.054235 DBDB 0.047226 0.107065 0.801571 0.816877 0.556934 AXXH 0.862611 0.439051 0.083341 0.389785 0.258748 BXED 0.643533 0.082176 0.167241 0.405304 0.088063 FXGE 0.279076 0.000998 0.949414 0.303408 0.009342 AHDC 0.617194 0.272401 0.252663 0.788798 0.130996 CXGA 0.104552 0.895106 0.414877 0.167643 0.454175 BDBA 0.045650 0.926742 0.454097 0.055006 0.939082 HBDC 0.069192 0.797224 0.943648 0.567334 0.044285 EBBX 0.383365 0.852788 0.679330 0.418570 0.817291","title":"2. To create new  DataFrame from  list of dictionaries."},{"location":"CreateDF/createdf/#3-to-create-dataframe-from-a-list","text":"A = [random . uniform( 0 , 1 ) for i in range ( 10 )] B = [random . uniform( 0 , 1 ) for i in range ( 10 )] C = [random . uniform( 0 , 1 ) for i in range ( 10 )] D = [random . uniform( 0 , 1 ) for i in range ( 10 )] df = pd . DataFrame() df[ 'A' ],df[ 'B' ],df[ 'C' ],df[ 'D' ] = A,B,C,D df . head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } A B C D 0 0.816389 0.212530 0.705185 0.225743 1 0.646496 0.876869 0.648350 0.788687 2 0.869173 0.832004 0.516009 0.917783 3 0.668866 0.778850 0.834528 0.243842 4 0.742311 0.984313 0.872512 0.451476","title":"3. To create DataFrame from a List :"},{"location":"CreateDF/createdf/#references","text":"Pydata document for Styling DataFrame visualization","title":"References:"},{"location":"DataFrame/dataframe/","text":"DataFrame Introduction In this notebook, we will learn to load the data and look at top row of the data, shape (i.e., number of rows and columns) of the data, list of name of columns, list of name of index and summary of data statistics (e.g., mean, standard deviation, median). import pandas as pd import numpy as np import seaborn as sns import matplotlib.pyplot as plt % matplotlib inline sns . set() 1. Creating DataFrame by loading data To load data to pandas DataFrame from csv file, we can use read_csv() functionality. Pandas DataFrame is an object. When we load data, DataFrame holds the data with extra functionality integrated into the DataFrme object. Once the data is loaded, we can set up one column as the index by set_index() function. Following is the defult setting of data upload with read_csv() : pandas.read_csv(filepath_or_buffer, sep=',', delimiter=None, header='infer', names=None, index_col=None, usecols=None, squeeze=False, prefix=None,...) titanic = pd . read_csv( 'data/titanic.csv' ) titanic = titanic . set_index( 'Name' ) To see top 3 row of data in the DataFrame . titanic . head( 3 ) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } PassengerId Survived Pclass Sex Age SibSp Parch Ticket Fare Cabin Embarked Name Braund, Mr. Owen Harris 1 0 3 male 22.0 1 0 A/5 21171 7.2500 NaN S Cumings, Mrs. John Bradley (Florence Briggs Thayer) 2 1 1 female 38.0 1 0 PC 17599 71.2833 C85 C Heikkinen, Miss. Laina 3 1 3 female 26.0 0 0 STON/O2. 3101282 7.9250 NaN S To know shape of the DataFrame : titanic . shape (891, 11) To find the list of column names: titanic . columns Index(['PassengerId', 'Survived', 'Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked'], dtype='object') To find the list of index name: titanic . index Index(['Braund, Mr. Owen Harris', 'Cumings, Mrs. John Bradley (Florence Briggs Thayer)', 'Heikkinen, Miss. Laina', 'Futrelle, Mrs. Jacques Heath (Lily May Peel)', 'Allen, Mr. William Henry', 'Moran, Mr. James', 'McCarthy, Mr. Timothy J', 'Palsson, Master. Gosta Leonard', 'Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)', 'Nasser, Mrs. Nicholas (Adele Achem)', ... 'Markun, Mr. Johann', 'Dahlberg, Miss. Gerda Ulrika', 'Banfield, Mr. Frederick James', 'Sutehall, Mr. Henry Jr', 'Rice, Mrs. William (Margaret Norton)', 'Montvila, Rev. Juozas', 'Graham, Miss. Margaret Edith', 'Johnston, Miss. Catherine Helen \"Carrie\"', 'Behr, Mr. Karl Howell', 'Dooley, Mr. Patrick'], dtype='object', name='Name', length=891) To find preliminary satatistics of the each column of the DataFrame . titanic . describe() . T .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } count mean std min 25% 50% 75% max PassengerId 891.0 446.000000 257.353842 1.00 223.5000 446.0000 668.5 891.0000 Survived 891.0 0.383838 0.486592 0.00 0.0000 0.0000 1.0 1.0000 Pclass 891.0 2.308642 0.836071 1.00 2.0000 3.0000 3.0 3.0000 Age 714.0 29.699118 14.526497 0.42 20.1250 28.0000 38.0 80.0000 SibSp 891.0 0.523008 1.102743 0.00 0.0000 0.0000 1.0 8.0000 Parch 891.0 0.381594 0.806057 0.00 0.0000 0.0000 0.0 6.0000 Fare 891.0 32.204208 49.693429 0.00 7.9104 14.4542 31.0 512.3292 Styling data sample visualization: cm = sns . light_palette( \"green\" , as_cmap = True ) s = titanic[ 0 : 5 ] . style . background_gradient(cmap = cm) s #T_ee022e9c_100c_11eb_9d23_3052cb51cf96row0_col0 { background-color: #e5ffe5; color: #000000; } #T_ee022e9c_100c_11eb_9d23_3052cb51cf96row0_col1 { background-color: #e5ffe5; color: #000000; } #T_ee022e9c_100c_11eb_9d23_3052cb51cf96row0_col2 { background-color: #008000; color: #f1f1f1; } #T_ee022e9c_100c_11eb_9d23_3052cb51cf96row0_col4 { background-color: #e5ffe5; color: #000000; } #T_ee022e9c_100c_11eb_9d23_3052cb51cf96row0_col5 { background-color: #008000; color: #f1f1f1; } #T_ee022e9c_100c_11eb_9d23_3052cb51cf96row0_col6 { background-color: #e5ffe5; color: #000000; } #T_ee022e9c_100c_11eb_9d23_3052cb51cf96row0_col8 { background-color: #e5ffe5; color: #000000; } #T_ee022e9c_100c_11eb_9d23_3052cb51cf96row1_col0 { background-color: #acdfac; color: #000000; } #T_ee022e9c_100c_11eb_9d23_3052cb51cf96row1_col1 { background-color: #008000; color: #f1f1f1; } #T_ee022e9c_100c_11eb_9d23_3052cb51cf96row1_col2 { background-color: #e5ffe5; color: #000000; } #T_ee022e9c_100c_11eb_9d23_3052cb51cf96row1_col4 { background-color: #008000; color: #f1f1f1; } #T_ee022e9c_100c_11eb_9d23_3052cb51cf96row1_col5 { background-color: #008000; color: #f1f1f1; } #T_ee022e9c_100c_11eb_9d23_3052cb51cf96row1_col6 { background-color: #e5ffe5; color: #000000; } #T_ee022e9c_100c_11eb_9d23_3052cb51cf96row1_col8 { background-color: #008000; color: #f1f1f1; } #T_ee022e9c_100c_11eb_9d23_3052cb51cf96row2_col0 { background-color: #72bf72; color: #000000; } #T_ee022e9c_100c_11eb_9d23_3052cb51cf96row2_col1 { background-color: #008000; color: #f1f1f1; } #T_ee022e9c_100c_11eb_9d23_3052cb51cf96row2_col2 { background-color: #008000; color: #f1f1f1; } #T_ee022e9c_100c_11eb_9d23_3052cb51cf96row2_col4 { background-color: #acdfac; color: #000000; } #T_ee022e9c_100c_11eb_9d23_3052cb51cf96row2_col5 { background-color: #e5ffe5; color: #000000; } #T_ee022e9c_100c_11eb_9d23_3052cb51cf96row2_col6 { background-color: #e5ffe5; color: #000000; } #T_ee022e9c_100c_11eb_9d23_3052cb51cf96row2_col8 { background-color: #e4fee4; color: #000000; } #T_ee022e9c_100c_11eb_9d23_3052cb51cf96row3_col0 { background-color: #399f39; color: #000000; } #T_ee022e9c_100c_11eb_9d23_3052cb51cf96row3_col1 { background-color: #008000; color: #f1f1f1; } #T_ee022e9c_100c_11eb_9d23_3052cb51cf96row3_col2 { background-color: #e5ffe5; color: #000000; } #T_ee022e9c_100c_11eb_9d23_3052cb51cf96row3_col4 { background-color: #2a972a; color: #000000; } #T_ee022e9c_100c_11eb_9d23_3052cb51cf96row3_col5 { background-color: #008000; color: #f1f1f1; } #T_ee022e9c_100c_11eb_9d23_3052cb51cf96row3_col6 { background-color: #e5ffe5; color: #000000; } #T_ee022e9c_100c_11eb_9d23_3052cb51cf96row3_col8 { background-color: #41a441; color: #000000; } #T_ee022e9c_100c_11eb_9d23_3052cb51cf96row4_col0 { background-color: #008000; color: #f1f1f1; } #T_ee022e9c_100c_11eb_9d23_3052cb51cf96row4_col1 { background-color: #e5ffe5; color: #000000; } #T_ee022e9c_100c_11eb_9d23_3052cb51cf96row4_col2 { background-color: #008000; color: #f1f1f1; } #T_ee022e9c_100c_11eb_9d23_3052cb51cf96row4_col4 { background-color: #2a972a; color: #000000; } #T_ee022e9c_100c_11eb_9d23_3052cb51cf96row4_col5 { background-color: #e5ffe5; color: #000000; } #T_ee022e9c_100c_11eb_9d23_3052cb51cf96row4_col6 { background-color: #e5ffe5; color: #000000; } #T_ee022e9c_100c_11eb_9d23_3052cb51cf96row4_col8 { background-color: #e3fee3; color: #000000; } PassengerId Survived Pclass Sex Age SibSp Parch Ticket Fare Cabin Embarked Name Braund, Mr. Owen Harris 1 0 3 male 22 1 0 A/5 21171 7.25 nan S Cumings, Mrs. John Bradley (Florence Briggs Thayer) 2 1 1 female 38 1 0 PC 17599 71.2833 C85 C Heikkinen, Miss. Laina 3 1 3 female 26 0 0 STON/O2. 3101282 7.925 nan S Futrelle, Mrs. Jacques Heath (Lily May Peel) 4 1 1 female 35 1 0 113803 53.1 C123 S Allen, Mr. William Henry 5 0 3 male 35 0 0 373450 8.05 nan S To drop a column from a DataFrame : titanic = titanic . drop( 'Ticket' , axis = 1 ) titanic . head( 2 ) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } PassengerId Survived Pclass Sex Age SibSp Parch Fare Cabin Embarked Name Braund, Mr. Owen Harris 1 0 3 male 22.0 1 0 7.2500 NaN S Cumings, Mrs. John Bradley (Florence Briggs Thayer) 2 1 1 female 38.0 1 0 71.2833 C85 C To drop the row data if there is NaN value: titanic = titanic . dropna(axis = 0 ) titanic . head( 2 ) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } PassengerId Survived Pclass Sex Age SibSp Parch Fare Cabin Embarked Name Cumings, Mrs. John Bradley (Florence Briggs Thayer) 2 1 1 female 38.0 1 0 71.2833 C85 C Futrelle, Mrs. Jacques Heath (Lily May Peel) 4 1 1 female 35.0 1 0 53.1000 C123 S To fill the NaN value with 0. df = pd . DataFrame([[np . nan, 2 , np . nan, 0 ], [ 3 , 4 , np . nan, 1 ], [np . nan, np . nan, np . nan, 5 ], [np . nan, 3 , np . nan, 4 ]], columns = list ( 'ABCD' )) df = df . fillna( 0 ) df .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } A B C D 0 0.0 2.0 0.0 0 1 3.0 4.0 0.0 1 2 0.0 0.0 0.0 5 3 0.0 3.0 0.0 4 To invert or transpose the DataFrame : df . T .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 0 1 2 3 A 0.0 3.0 0.0 0.0 B 2.0 4.0 0.0 3.0 C 0.0 0.0 0.0 0.0 D 0.0 1.0 5.0 4.0 References: Pydata document for Styling DataFrame visualization Pandas API References","title":"Dataframe Introduction"},{"location":"DataFrame/dataframe/#dataframe-introduction","text":"In this notebook, we will learn to load the data and look at top row of the data, shape (i.e., number of rows and columns) of the data, list of name of columns, list of name of index and summary of data statistics (e.g., mean, standard deviation, median). import pandas as pd import numpy as np import seaborn as sns import matplotlib.pyplot as plt % matplotlib inline sns . set()","title":"DataFrame Introduction"},{"location":"DataFrame/dataframe/#1-creating-dataframe-by-loading-data","text":"To load data to pandas DataFrame from csv file, we can use read_csv() functionality. Pandas DataFrame is an object. When we load data, DataFrame holds the data with extra functionality integrated into the DataFrme object. Once the data is loaded, we can set up one column as the index by set_index() function. Following is the defult setting of data upload with read_csv() : pandas.read_csv(filepath_or_buffer, sep=',', delimiter=None, header='infer', names=None, index_col=None, usecols=None, squeeze=False, prefix=None,...) titanic = pd . read_csv( 'data/titanic.csv' ) titanic = titanic . set_index( 'Name' ) To see top 3 row of data in the DataFrame . titanic . head( 3 ) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } PassengerId Survived Pclass Sex Age SibSp Parch Ticket Fare Cabin Embarked Name Braund, Mr. Owen Harris 1 0 3 male 22.0 1 0 A/5 21171 7.2500 NaN S Cumings, Mrs. John Bradley (Florence Briggs Thayer) 2 1 1 female 38.0 1 0 PC 17599 71.2833 C85 C Heikkinen, Miss. Laina 3 1 3 female 26.0 0 0 STON/O2. 3101282 7.9250 NaN S To know shape of the DataFrame : titanic . shape (891, 11) To find the list of column names: titanic . columns Index(['PassengerId', 'Survived', 'Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked'], dtype='object') To find the list of index name: titanic . index Index(['Braund, Mr. Owen Harris', 'Cumings, Mrs. John Bradley (Florence Briggs Thayer)', 'Heikkinen, Miss. Laina', 'Futrelle, Mrs. Jacques Heath (Lily May Peel)', 'Allen, Mr. William Henry', 'Moran, Mr. James', 'McCarthy, Mr. Timothy J', 'Palsson, Master. Gosta Leonard', 'Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)', 'Nasser, Mrs. Nicholas (Adele Achem)', ... 'Markun, Mr. Johann', 'Dahlberg, Miss. Gerda Ulrika', 'Banfield, Mr. Frederick James', 'Sutehall, Mr. Henry Jr', 'Rice, Mrs. William (Margaret Norton)', 'Montvila, Rev. Juozas', 'Graham, Miss. Margaret Edith', 'Johnston, Miss. Catherine Helen \"Carrie\"', 'Behr, Mr. Karl Howell', 'Dooley, Mr. Patrick'], dtype='object', name='Name', length=891) To find preliminary satatistics of the each column of the DataFrame . titanic . describe() . T .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } count mean std min 25% 50% 75% max PassengerId 891.0 446.000000 257.353842 1.00 223.5000 446.0000 668.5 891.0000 Survived 891.0 0.383838 0.486592 0.00 0.0000 0.0000 1.0 1.0000 Pclass 891.0 2.308642 0.836071 1.00 2.0000 3.0000 3.0 3.0000 Age 714.0 29.699118 14.526497 0.42 20.1250 28.0000 38.0 80.0000 SibSp 891.0 0.523008 1.102743 0.00 0.0000 0.0000 1.0 8.0000 Parch 891.0 0.381594 0.806057 0.00 0.0000 0.0000 0.0 6.0000 Fare 891.0 32.204208 49.693429 0.00 7.9104 14.4542 31.0 512.3292 Styling data sample visualization: cm = sns . light_palette( \"green\" , as_cmap = True ) s = titanic[ 0 : 5 ] . style . background_gradient(cmap = cm) s #T_ee022e9c_100c_11eb_9d23_3052cb51cf96row0_col0 { background-color: #e5ffe5; color: #000000; } #T_ee022e9c_100c_11eb_9d23_3052cb51cf96row0_col1 { background-color: #e5ffe5; color: #000000; } #T_ee022e9c_100c_11eb_9d23_3052cb51cf96row0_col2 { background-color: #008000; color: #f1f1f1; } #T_ee022e9c_100c_11eb_9d23_3052cb51cf96row0_col4 { background-color: #e5ffe5; color: #000000; } #T_ee022e9c_100c_11eb_9d23_3052cb51cf96row0_col5 { background-color: #008000; color: #f1f1f1; } #T_ee022e9c_100c_11eb_9d23_3052cb51cf96row0_col6 { background-color: #e5ffe5; color: #000000; } #T_ee022e9c_100c_11eb_9d23_3052cb51cf96row0_col8 { background-color: #e5ffe5; color: #000000; } #T_ee022e9c_100c_11eb_9d23_3052cb51cf96row1_col0 { background-color: #acdfac; color: #000000; } #T_ee022e9c_100c_11eb_9d23_3052cb51cf96row1_col1 { background-color: #008000; color: #f1f1f1; } #T_ee022e9c_100c_11eb_9d23_3052cb51cf96row1_col2 { background-color: #e5ffe5; color: #000000; } #T_ee022e9c_100c_11eb_9d23_3052cb51cf96row1_col4 { background-color: #008000; color: #f1f1f1; } #T_ee022e9c_100c_11eb_9d23_3052cb51cf96row1_col5 { background-color: #008000; color: #f1f1f1; } #T_ee022e9c_100c_11eb_9d23_3052cb51cf96row1_col6 { background-color: #e5ffe5; color: #000000; } #T_ee022e9c_100c_11eb_9d23_3052cb51cf96row1_col8 { background-color: #008000; color: #f1f1f1; } #T_ee022e9c_100c_11eb_9d23_3052cb51cf96row2_col0 { background-color: #72bf72; color: #000000; } #T_ee022e9c_100c_11eb_9d23_3052cb51cf96row2_col1 { background-color: #008000; color: #f1f1f1; } #T_ee022e9c_100c_11eb_9d23_3052cb51cf96row2_col2 { background-color: #008000; color: #f1f1f1; } #T_ee022e9c_100c_11eb_9d23_3052cb51cf96row2_col4 { background-color: #acdfac; color: #000000; } #T_ee022e9c_100c_11eb_9d23_3052cb51cf96row2_col5 { background-color: #e5ffe5; color: #000000; } #T_ee022e9c_100c_11eb_9d23_3052cb51cf96row2_col6 { background-color: #e5ffe5; color: #000000; } #T_ee022e9c_100c_11eb_9d23_3052cb51cf96row2_col8 { background-color: #e4fee4; color: #000000; } #T_ee022e9c_100c_11eb_9d23_3052cb51cf96row3_col0 { background-color: #399f39; color: #000000; } #T_ee022e9c_100c_11eb_9d23_3052cb51cf96row3_col1 { background-color: #008000; color: #f1f1f1; } #T_ee022e9c_100c_11eb_9d23_3052cb51cf96row3_col2 { background-color: #e5ffe5; color: #000000; } #T_ee022e9c_100c_11eb_9d23_3052cb51cf96row3_col4 { background-color: #2a972a; color: #000000; } #T_ee022e9c_100c_11eb_9d23_3052cb51cf96row3_col5 { background-color: #008000; color: #f1f1f1; } #T_ee022e9c_100c_11eb_9d23_3052cb51cf96row3_col6 { background-color: #e5ffe5; color: #000000; } #T_ee022e9c_100c_11eb_9d23_3052cb51cf96row3_col8 { background-color: #41a441; color: #000000; } #T_ee022e9c_100c_11eb_9d23_3052cb51cf96row4_col0 { background-color: #008000; color: #f1f1f1; } #T_ee022e9c_100c_11eb_9d23_3052cb51cf96row4_col1 { background-color: #e5ffe5; color: #000000; } #T_ee022e9c_100c_11eb_9d23_3052cb51cf96row4_col2 { background-color: #008000; color: #f1f1f1; } #T_ee022e9c_100c_11eb_9d23_3052cb51cf96row4_col4 { background-color: #2a972a; color: #000000; } #T_ee022e9c_100c_11eb_9d23_3052cb51cf96row4_col5 { background-color: #e5ffe5; color: #000000; } #T_ee022e9c_100c_11eb_9d23_3052cb51cf96row4_col6 { background-color: #e5ffe5; color: #000000; } #T_ee022e9c_100c_11eb_9d23_3052cb51cf96row4_col8 { background-color: #e3fee3; color: #000000; } PassengerId Survived Pclass Sex Age SibSp Parch Ticket Fare Cabin Embarked Name Braund, Mr. Owen Harris 1 0 3 male 22 1 0 A/5 21171 7.25 nan S Cumings, Mrs. John Bradley (Florence Briggs Thayer) 2 1 1 female 38 1 0 PC 17599 71.2833 C85 C Heikkinen, Miss. Laina 3 1 3 female 26 0 0 STON/O2. 3101282 7.925 nan S Futrelle, Mrs. Jacques Heath (Lily May Peel) 4 1 1 female 35 1 0 113803 53.1 C123 S Allen, Mr. William Henry 5 0 3 male 35 0 0 373450 8.05 nan S To drop a column from a DataFrame : titanic = titanic . drop( 'Ticket' , axis = 1 ) titanic . head( 2 ) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } PassengerId Survived Pclass Sex Age SibSp Parch Fare Cabin Embarked Name Braund, Mr. Owen Harris 1 0 3 male 22.0 1 0 7.2500 NaN S Cumings, Mrs. John Bradley (Florence Briggs Thayer) 2 1 1 female 38.0 1 0 71.2833 C85 C To drop the row data if there is NaN value: titanic = titanic . dropna(axis = 0 ) titanic . head( 2 ) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } PassengerId Survived Pclass Sex Age SibSp Parch Fare Cabin Embarked Name Cumings, Mrs. John Bradley (Florence Briggs Thayer) 2 1 1 female 38.0 1 0 71.2833 C85 C Futrelle, Mrs. Jacques Heath (Lily May Peel) 4 1 1 female 35.0 1 0 53.1000 C123 S To fill the NaN value with 0. df = pd . DataFrame([[np . nan, 2 , np . nan, 0 ], [ 3 , 4 , np . nan, 1 ], [np . nan, np . nan, np . nan, 5 ], [np . nan, 3 , np . nan, 4 ]], columns = list ( 'ABCD' )) df = df . fillna( 0 ) df .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } A B C D 0 0.0 2.0 0.0 0 1 3.0 4.0 0.0 1 2 0.0 0.0 0.0 5 3 0.0 3.0 0.0 4 To invert or transpose the DataFrame : df . T .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 0 1 2 3 A 0.0 3.0 0.0 0.0 B 2.0 4.0 0.0 3.0 C 0.0 0.0 0.0 0.0 D 0.0 1.0 5.0 4.0","title":"1. Creating DataFrame by loading data"},{"location":"DataFrame/dataframe/#references","text":"Pydata document for Styling DataFrame visualization Pandas API References","title":"References:"},{"location":"GroupBy/groupby/","text":"Groupby and Aggregation (Split-Apply-Combine): This notebook will provide a walkthrough for data splitting (mapping) with groupby() , apply some action (e.g., count(), sum(), mean(), std() ) and finally combine through aggregation(), transform() action (reduction). Read more about these functionality from Pydata documentation for Group by (split-apply-combine) [1]. Some parts of this notebook are taken from EuroScipy 2016 Pandas Tutorial by Joris Van den Bossche and Nicholas Devenish [2] import pandas as pd import numpy as np import seaborn as sns import matplotlib.pyplot as plt % matplotlib inline sns . set() Load data titanic = pd . read_csv( 'data/titanic.csv' ) titanic = titanic . set_index( 'Name' ) titanic . head( 2 ) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } PassengerId Survived Pclass Sex Age SibSp Parch Ticket Fare Cabin Embarked Name Braund, Mr. Owen Harris 1 0 3 male 22.0 1 0 A/5 21171 7.2500 NaN S Cumings, Mrs. John Bradley (Florence Briggs Thayer) 2 1 1 female 38.0 1 0 PC 17599 71.2833 C85 C The groupby operation (split-apply-combine) is followed by multiple functionality e.g., groupby.aggregate() , groupby.count() groupby.size() , groupby.mean() . The \"group by\" concept: we want to apply the same function on subsets of your dataframe, based on some key to split the dataframe in subsets This operation is also referred to as the \"split-apply-combine\" operation, involving the following steps: Splitting the data into groups based on some criteria Applying a function to each group independently Combining the results into a data structure 1. Simple Groupby and aggregate example: Lets create a sample dataframe to operate groupby() followed by size() and aggregate() with np.sum() seperately. df = pd . DataFrame({ 'key' :[ 'A' , 'B' , 'C' , 'A' , 'B' , 'C' , 'A' , 'B' , 'C' ], 'data' : [ 0 , 5 , 10 , 5 , 10 , 15 , 10 , 15 , 20 ]}) df . head( 2 ) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } key data 0 A 0 1 B 5 The groupby() operation followed by size() does not return a DataFrame object, it becomes a pandas Series object. result = df . groupby( 'key' ) . size() print ( \"Object type:\" , type (result)) print (result) Object type: <class 'pandas.core.series.Series'> key A 3 B 3 C 3 dtype: int64 The groupby() operation followed by aggregate() returns a DataFrame object. result = df . groupby( 'key' ) . aggregate(np . sum) print ( \"object type:\" , type (result)) result object type: <class 'pandas.core.frame.DataFrame'> .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } data key A 15 B 30 C 45 2. Exercise with Titanic Dataset EXERCISE : Using groupby(), calculate the total number for each sex catagory. titanic . groupby( 'Sex' ) . size() Sex female 314 male 577 dtype: int64 EXERCISE : Using groupby(), calculate the average age for each sex. titanic . groupby( 'Sex' )[ 'Age' ] . mean() Sex female 27.915709 male 30.726645 Name: Age, dtype: float64 EXERCISE : Calculate the average survival ratio for all passengers. titanic[ 'Survived' ] . sum() / len (titanic[ 'Survived' ]) 0.3838383838383838 EXERCISE : Calculate this survival ratio for all passengers younger that 25 (remember: filtering/boolean indexing). df25 = titanic[titanic_df1[ 'Age' ] <= 25 ] df25[ 'Survived' ] . sum() / len (df25[ 'Survived' ]) 0.4119601328903654 EXERCISE : Is there a difference in this survival ratio between the sexes? (tip: write the above calculation of the survival ratio as a function) def survival_ratio (survived): return survived . sum() / len (survived) titanic . groupby( 'Sex' )[ 'Survived' ] . aggregate(survival_ratio) Sex female 0.742038 male 0.188908 Name: Survived, dtype: float64 EXERCISE : Make a bar plot of the survival ratio for the different classes ('Pclass' column). titanic . groupby( 'Pclass' )[ 'Survived' ] . aggregate(survival_ratio) . plot(kind = 'bar' ) pass 3. Some advanced groupby operations EXERCISE : Find data for age distribution. df = titanic . copy(deep = True ) df . groupby(df . Age // 10 * 10 ) . size() . plot(kind = 'bar' ,figsize = [ 6 , 4 ]) pass EXERCISE : Find data for male age distribution. Male = df[df[ 'Sex' ] == 'male' ] Male . groupby(Male . Age // 10 * 10 ) . size() . plot(kind = 'bar' ,figsize = [ 6 , 4 ]) pass EXERCISE : List data with Fare size greater then 50. Fare50 = df[df . Fare > 50 ] Fare50 . groupby([ 'Sex' ]) . size() Sex female 87 male 73 dtype: int64 Fare50 . groupby([ 'Age' , 'Sex' , 'Survived' ]) . size() . head( 4 ) Age Sex Survived 0.92 male 1 1 2.00 female 0 1 4.00 male 1 1 11.00 male 1 1 dtype: int64 4. Groupby followed by transformation: groupby.transform() . The transform operation accepts builting functions e.g., sum, mean, std through keyword. One can define a new function called user defined function to supply inside transform(new_function) . df = pd . DataFrame({ 'key' :[ 'A' , 'B' , 'C' , 'A' , 'B' , 'C' , 'A' , 'B' , 'C' ], 'data' : [ 0 , 5 , 10 , 5 , 10 , 15 , 10 , 15 , 20 ]}) df . head( 2 ) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } key data 0 A 0 1 B 5 df . groupby( 'key' ) . transform( 'mean' ) . head( 2 ) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } data 0 5 1 10 def normalize (group): return (group - group . mean()) / group . std() df . groupby( 'key' ) . transform(normalize) . head( 2 ) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } data 0 -1.0 1 -1.0 References: Pydata documentation: Group by: split-apply-combine EuroScipy 2016 Pandas Tutorial by Joris Van den Bossche and Nicholas Devenish","title":"GroupBy and Aggregate, Transform"},{"location":"GroupBy/groupby/#groupby-and-aggregation-split-apply-combine","text":"This notebook will provide a walkthrough for data splitting (mapping) with groupby() , apply some action (e.g., count(), sum(), mean(), std() ) and finally combine through aggregation(), transform() action (reduction). Read more about these functionality from Pydata documentation for Group by (split-apply-combine) [1]. Some parts of this notebook are taken from EuroScipy 2016 Pandas Tutorial by Joris Van den Bossche and Nicholas Devenish [2] import pandas as pd import numpy as np import seaborn as sns import matplotlib.pyplot as plt % matplotlib inline sns . set()","title":"Groupby and Aggregation (Split-Apply-Combine):"},{"location":"GroupBy/groupby/#load-data","text":"titanic = pd . read_csv( 'data/titanic.csv' ) titanic = titanic . set_index( 'Name' ) titanic . head( 2 ) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } PassengerId Survived Pclass Sex Age SibSp Parch Ticket Fare Cabin Embarked Name Braund, Mr. Owen Harris 1 0 3 male 22.0 1 0 A/5 21171 7.2500 NaN S Cumings, Mrs. John Bradley (Florence Briggs Thayer) 2 1 1 female 38.0 1 0 PC 17599 71.2833 C85 C","title":"Load data"},{"location":"GroupBy/groupby/#the-groupby-operation-split-apply-combine","text":"is followed by multiple functionality e.g., groupby.aggregate() , groupby.count() groupby.size() , groupby.mean() . The \"group by\" concept: we want to apply the same function on subsets of your dataframe, based on some key to split the dataframe in subsets This operation is also referred to as the \"split-apply-combine\" operation, involving the following steps: Splitting the data into groups based on some criteria Applying a function to each group independently Combining the results into a data structure","title":"The groupby operation (split-apply-combine)"},{"location":"GroupBy/groupby/#1-simple-groupby-and-aggregate-example","text":"Lets create a sample dataframe to operate groupby() followed by size() and aggregate() with np.sum() seperately. df = pd . DataFrame({ 'key' :[ 'A' , 'B' , 'C' , 'A' , 'B' , 'C' , 'A' , 'B' , 'C' ], 'data' : [ 0 , 5 , 10 , 5 , 10 , 15 , 10 , 15 , 20 ]}) df . head( 2 ) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } key data 0 A 0 1 B 5 The groupby() operation followed by size() does not return a DataFrame object, it becomes a pandas Series object. result = df . groupby( 'key' ) . size() print ( \"Object type:\" , type (result)) print (result) Object type: <class 'pandas.core.series.Series'> key A 3 B 3 C 3 dtype: int64 The groupby() operation followed by aggregate() returns a DataFrame object. result = df . groupby( 'key' ) . aggregate(np . sum) print ( \"object type:\" , type (result)) result object type: <class 'pandas.core.frame.DataFrame'> .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } data key A 15 B 30 C 45","title":"1. Simple Groupby and aggregate example:"},{"location":"GroupBy/groupby/#2-exercise-with-titanic-dataset","text":"EXERCISE : Using groupby(), calculate the total number for each sex catagory. titanic . groupby( 'Sex' ) . size() Sex female 314 male 577 dtype: int64 EXERCISE : Using groupby(), calculate the average age for each sex. titanic . groupby( 'Sex' )[ 'Age' ] . mean() Sex female 27.915709 male 30.726645 Name: Age, dtype: float64 EXERCISE : Calculate the average survival ratio for all passengers. titanic[ 'Survived' ] . sum() / len (titanic[ 'Survived' ]) 0.3838383838383838 EXERCISE : Calculate this survival ratio for all passengers younger that 25 (remember: filtering/boolean indexing). df25 = titanic[titanic_df1[ 'Age' ] <= 25 ] df25[ 'Survived' ] . sum() / len (df25[ 'Survived' ]) 0.4119601328903654 EXERCISE : Is there a difference in this survival ratio between the sexes? (tip: write the above calculation of the survival ratio as a function) def survival_ratio (survived): return survived . sum() / len (survived) titanic . groupby( 'Sex' )[ 'Survived' ] . aggregate(survival_ratio) Sex female 0.742038 male 0.188908 Name: Survived, dtype: float64 EXERCISE : Make a bar plot of the survival ratio for the different classes ('Pclass' column). titanic . groupby( 'Pclass' )[ 'Survived' ] . aggregate(survival_ratio) . plot(kind = 'bar' ) pass","title":"2. Exercise with Titanic Dataset"},{"location":"GroupBy/groupby/#3-some-advanced-groupby-operations","text":"EXERCISE : Find data for age distribution. df = titanic . copy(deep = True ) df . groupby(df . Age // 10 * 10 ) . size() . plot(kind = 'bar' ,figsize = [ 6 , 4 ]) pass EXERCISE : Find data for male age distribution. Male = df[df[ 'Sex' ] == 'male' ] Male . groupby(Male . Age // 10 * 10 ) . size() . plot(kind = 'bar' ,figsize = [ 6 , 4 ]) pass EXERCISE : List data with Fare size greater then 50. Fare50 = df[df . Fare > 50 ] Fare50 . groupby([ 'Sex' ]) . size() Sex female 87 male 73 dtype: int64 Fare50 . groupby([ 'Age' , 'Sex' , 'Survived' ]) . size() . head( 4 ) Age Sex Survived 0.92 male 1 1 2.00 female 0 1 4.00 male 1 1 11.00 male 1 1 dtype: int64","title":"3. Some advanced groupby operations"},{"location":"GroupBy/groupby/#4-groupby-followed-by-transformation-groupbytransform","text":"The transform operation accepts builting functions e.g., sum, mean, std through keyword. One can define a new function called user defined function to supply inside transform(new_function) . df = pd . DataFrame({ 'key' :[ 'A' , 'B' , 'C' , 'A' , 'B' , 'C' , 'A' , 'B' , 'C' ], 'data' : [ 0 , 5 , 10 , 5 , 10 , 15 , 10 , 15 , 20 ]}) df . head( 2 ) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } key data 0 A 0 1 B 5 df . groupby( 'key' ) . transform( 'mean' ) . head( 2 ) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } data 0 5 1 10 def normalize (group): return (group - group . mean()) / group . std() df . groupby( 'key' ) . transform(normalize) . head( 2 ) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } data 0 -1.0 1 -1.0","title":"4. Groupby followed by transformation: groupby.transform()."},{"location":"GroupBy/groupby/#references","text":"Pydata documentation: Group by: split-apply-combine EuroScipy 2016 Pandas Tutorial by Joris Van den Bossche and Nicholas Devenish","title":"References:"},{"location":"Indexing/indexing/","text":"Data Iteration, Indexing and Filters In this notebook we will learn indexing DataFrame with loc and iloc functionality and slicing operation. Some Data Filtering techniques will also be conducted. Read more about these functionality from Pydata documentation for indexing [1]. Some parts of this notebook are taken from EuroScipy 2016 Pandas Tutorial by Joris Van den Bossche and Nicholas Devenish [2] import pandas as pd import numpy as np import seaborn as sns import matplotlib.pyplot as plt % matplotlib inline titanic = pd . read_csv( 'data/titanic.csv' ) titanic = titanic . set_index( \"Name\" ) titanic . head( 2 ) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } PassengerId Survived Pclass Sex Age SibSp Parch Ticket Fare Cabin Embarked Name Braund, Mr. Owen Harris 1 0 3 male 22.0 1 0 A/5 21171 7.2500 NaN S Cumings, Mrs. John Bradley (Florence Briggs Thayer) 2 1 1 female 38.0 1 0 PC 17599 71.2833 C85 C Lets create a small sample of data sample = titanic[ 0 : 5 ] 1. Iteration of rows implementing iterrows for index,row in sample . iterrows(): print (index, list (row)) Braund, Mr. Owen Harris [1, 0, 3, 'male', 22.0, 1, 0, 'A/5 21171', 7.25, nan, 'S'] Cumings, Mrs. John Bradley (Florence Briggs Thayer) [2, 1, 1, 'female', 38.0, 1, 0, 'PC 17599', 71.2833, 'C85', 'C'] Heikkinen, Miss. Laina [3, 1, 3, 'female', 26.0, 0, 0, 'STON/O2. 3101282', 7.925, nan, 'S'] Futrelle, Mrs. Jacques Heath (Lily May Peel) [4, 1, 1, 'female', 35.0, 1, 0, '113803', 53.1, 'C123', 'S'] Allen, Mr. William Henry [5, 0, 3, 'male', 35.0, 0, 0, '373450', 8.05, nan, 'S'] We can select specific columns by passing column names in row() input for index,row in sample . iterrows(): print (index,row[ 'Sex' ],row[ 'Age' ]) Braund, Mr. Owen Harris male 22.0 Cumings, Mrs. John Bradley (Florence Briggs Thayer) female 38.0 Heikkinen, Miss. Laina female 26.0 Futrelle, Mrs. Jacques Heath (Lily May Peel) female 35.0 Allen, Mr. William Henry male 35.0 2. Iteration of rows with iteritems for index,row in sample . T . iteritems(): print (index, list (row)) Braund, Mr. Owen Harris [1, 0, 3, 'male', 22.0, 1, 0, 'A/5 21171', 7.25, nan, 'S'] Cumings, Mrs. John Bradley (Florence Briggs Thayer) [2, 1, 1, 'female', 38.0, 1, 0, 'PC 17599', 71.2833, 'C85', 'C'] Heikkinen, Miss. Laina [3, 1, 3, 'female', 26.0, 0, 0, 'STON/O2. 3101282', 7.925, nan, 'S'] Futrelle, Mrs. Jacques Heath (Lily May Peel) [4, 1, 1, 'female', 35.0, 1, 0, '113803', 53.1, 'C123', 'S'] Allen, Mr. William Henry [5, 0, 3, 'male', 35.0, 0, 0, '373450', 8.05, nan, 'S'] for index,row in sample . iteritems(): print (index,row[ 0 ],row[ 1 ],row[ 2 ]) PassengerId 1 2 3 Survived 0 1 1 Pclass 3 1 3 Sex male female female Age 22.0 38.0 26.0 SibSp 1 1 0 Parch 0 0 0 Ticket A/5 21171 PC 17599 STON/O2. 3101282 Fare 7.25 71.2833 7.925 Cabin nan C85 nan Embarked S C S 3. Indexing Data Source: Using iloc, loc, & ix to select rows and columns in Pandas DataFrames loc and iloc : The iloc indexer for Pandas Dataframe is used for integer-location based indexing / selection by position. The Pandas loc indexer can be used with DataFrames for two different use cases: a.) Selecting rows by label/index b.) Selecting rows with a boolean / conditional lookup sample . iloc[ 0 : 2 ,:] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } PassengerId Survived Pclass Sex Age SibSp Parch Ticket Fare Cabin Embarked Name Braund, Mr. Owen Harris 1 0 3 male 22.0 1 0 A/5 21171 7.2500 NaN S Cumings, Mrs. John Bradley (Florence Briggs Thayer) 2 1 1 female 38.0 1 0 PC 17599 71.2833 C85 C sample . iloc[ 1 , 0 : 3 ] PassengerId 2 Survived 1 Pclass 1 Name: Cumings, Mrs. John Bradley (Florence Briggs Thayer), dtype: object sample . loc[:, 'Survived' : 'Ticket' ] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Survived Pclass Sex Age SibSp Parch Ticket Name Braund, Mr. Owen Harris 0 3 male 22.0 1 0 A/5 21171 Cumings, Mrs. John Bradley (Florence Briggs Thayer) 1 1 female 38.0 1 0 PC 17599 Heikkinen, Miss. Laina 1 3 female 26.0 0 0 STON/O2. 3101282 Futrelle, Mrs. Jacques Heath (Lily May Peel) 1 1 female 35.0 1 0 113803 Allen, Mr. William Henry 0 3 male 35.0 0 0 373450 sample . loc[ 'Braund, Mr. Owen Harris' ,:] PassengerId 1 Survived 0 Pclass 3 Sex male Age 22 SibSp 1 Parch 0 Ticket A/5 21171 Fare 7.25 Cabin NaN Embarked S Name: Braund, Mr. Owen Harris, dtype: object 4 - Data Filters: Data Filters can be performed by either selecting specific set of column names or by seting boolean filters . Dictionary to DataFrame data = { 'country' : [ 'Belgium' , 'France' , 'Germany' , 'Netherlands' , 'United Kingdom' ], 'population' : [ 11.3 , 64.3 , 81.3 , 16.9 , 64.9 ], 'area' : [ 30510 , 671308 , 357050 , 41526 , 244820 ], 'capital' : [ 'Brussels' , 'Paris' , 'Berlin' , 'Amsterdam' , 'London' ]} countries = pd . DataFrame(data) countries .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } country population area capital 0 Belgium 11.3 30510 Brussels 1 France 64.3 671308 Paris 2 Germany 81.3 357050 Berlin 3 Netherlands 16.9 41526 Amsterdam 4 United Kingdom 64.9 244820 London To set the country as index: countries = countries . set_index( 'country' ) countries .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } population area capital country Belgium 11.3 30510 Brussels France 64.3 671308 Paris Germany 81.3 357050 Berlin Netherlands 16.9 41526 Amsterdam United Kingdom 64.9 244820 London To find the area of each country: countries[ 'area' ] country Belgium 30510 France 671308 Germany 357050 Netherlands 41526 United Kingdom 244820 Name: area, dtype: int64 To create a list instead of pandas Series object. Area = list (countries[ 'area' ]) Area [30510, 671308, 357050, 41526, 244820] To create a sub-DataFrame by choosing area and population countries[[ 'area' , 'population' ]] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } area population country Belgium 30510 11.3 France 671308 64.3 Germany 357050 81.3 Netherlands 41526 16.9 United Kingdom 244820 64.9 To observe slice of data by index names. countries[ 'France' : 'Netherlands' ] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } population area capital country France 64.3 671308 Paris Germany 81.3 357050 Berlin Netherlands 16.9 41526 Amsterdam To observe the data at specific row identified by index name(s) and spefic column identified by column name(s): countries . loc[ 'Germany' , 'area' ] 357050 countries . loc[ 'France' : 'Germany' , [ 'area' , 'population' ]] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } area population country France 671308 64.3 Germany 357050 81.3 To set boolean selection for subDataFrame : countries[ 'area' ] > 100000 country Belgium False France True Germany True Netherlands False United Kingdom True Name: area, dtype: bool countries[countries[ 'area' ] > 100000 ] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } population area capital country France 64.3 671308 Paris Germany 81.3 357050 Berlin United Kingdom 64.9 244820 London 5. Exercises: EXERCISE : Add a column `density` with the population density (note: population column is expressed in millions) countries[ 'density' ] = countries[ 'population' ] * 1000000 / countries[ 'area' ] countries .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } population area capital density country Belgium 11.3 30510 Brussels 370.370370 France 64.3 671308 Paris 95.783158 Germany 81.3 357050 Berlin 227.699202 Netherlands 16.9 41526 Amsterdam 406.973944 United Kingdom 64.9 244820 London 265.092721 EXERCISE : Select the capital and the population column of those countries where the density is larger than 300 countries . loc[countries[ 'density' ] > 300 , [ 'capital' , 'population' ]] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } capital population country Belgium Brussels 11.3 Netherlands Amsterdam 16.9 EXERCISE : Add a column 'density_ratio' with the ratio of the density to the mean density countries[ 'density_ratio' ] = countries[ 'density' ] / countries[ 'density' ] . mean() countries .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } population area capital density density_ratio country Belgium 11.3 30510 Brussels 370.370370 1.355755 France 64.3 671308 Paris 95.783158 0.350618 Germany 81.3 357050 Berlin 227.699202 0.833502 Netherlands 16.9 41526 Amsterdam 406.973944 1.489744 United Kingdom 64.9 244820 London 265.092721 0.970382 EXERCISE : Change the capital of the UK to Cambridge countries . loc[ 'United Kingdom' , 'capital' ] = 'Cambridge' countries .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } population area capital density density_ratio country Belgium 11.3 30510 Brussels 370.370370 1.355755 France 64.3 671308 Paris 95.783158 0.350618 Germany 81.3 357050 Berlin 227.699202 0.833502 Netherlands 16.9 41526 Amsterdam 406.973944 1.489744 United Kingdom 64.9 244820 Cambridge 265.092721 0.970382 EXERCISE : Select all countries whose population density is between 100 and 300 people/km\u00b2 countries[(countries[ 'density' ] > 100 ) & (countries[ 'density' ] < 300 )] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } population area capital density density_ratio country Germany 81.3 357050 Berlin 227.699202 0.833502 United Kingdom 64.9 244820 Cambridge 265.092721 0.970382 References: Pydata documentation: Group by: split-apply-combine EuroScipy 2016 Pandas Tutorial by Joris Van den Bossche and Nicholas Devenish","title":"Iteration, Indexing and Filter"},{"location":"Indexing/indexing/#data-iteration-indexing-and-filters","text":"In this notebook we will learn indexing DataFrame with loc and iloc functionality and slicing operation. Some Data Filtering techniques will also be conducted. Read more about these functionality from Pydata documentation for indexing [1]. Some parts of this notebook are taken from EuroScipy 2016 Pandas Tutorial by Joris Van den Bossche and Nicholas Devenish [2] import pandas as pd import numpy as np import seaborn as sns import matplotlib.pyplot as plt % matplotlib inline titanic = pd . read_csv( 'data/titanic.csv' ) titanic = titanic . set_index( \"Name\" ) titanic . head( 2 ) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } PassengerId Survived Pclass Sex Age SibSp Parch Ticket Fare Cabin Embarked Name Braund, Mr. Owen Harris 1 0 3 male 22.0 1 0 A/5 21171 7.2500 NaN S Cumings, Mrs. John Bradley (Florence Briggs Thayer) 2 1 1 female 38.0 1 0 PC 17599 71.2833 C85 C Lets create a small sample of data sample = titanic[ 0 : 5 ]","title":"Data Iteration, Indexing and Filters"},{"location":"Indexing/indexing/#1-iteration-of-rows-implementing-iterrows","text":"for index,row in sample . iterrows(): print (index, list (row)) Braund, Mr. Owen Harris [1, 0, 3, 'male', 22.0, 1, 0, 'A/5 21171', 7.25, nan, 'S'] Cumings, Mrs. John Bradley (Florence Briggs Thayer) [2, 1, 1, 'female', 38.0, 1, 0, 'PC 17599', 71.2833, 'C85', 'C'] Heikkinen, Miss. Laina [3, 1, 3, 'female', 26.0, 0, 0, 'STON/O2. 3101282', 7.925, nan, 'S'] Futrelle, Mrs. Jacques Heath (Lily May Peel) [4, 1, 1, 'female', 35.0, 1, 0, '113803', 53.1, 'C123', 'S'] Allen, Mr. William Henry [5, 0, 3, 'male', 35.0, 0, 0, '373450', 8.05, nan, 'S'] We can select specific columns by passing column names in row() input for index,row in sample . iterrows(): print (index,row[ 'Sex' ],row[ 'Age' ]) Braund, Mr. Owen Harris male 22.0 Cumings, Mrs. John Bradley (Florence Briggs Thayer) female 38.0 Heikkinen, Miss. Laina female 26.0 Futrelle, Mrs. Jacques Heath (Lily May Peel) female 35.0 Allen, Mr. William Henry male 35.0","title":"1. Iteration of rows implementing   iterrows"},{"location":"Indexing/indexing/#2-iteration-of-rows-with-iteritems","text":"for index,row in sample . T . iteritems(): print (index, list (row)) Braund, Mr. Owen Harris [1, 0, 3, 'male', 22.0, 1, 0, 'A/5 21171', 7.25, nan, 'S'] Cumings, Mrs. John Bradley (Florence Briggs Thayer) [2, 1, 1, 'female', 38.0, 1, 0, 'PC 17599', 71.2833, 'C85', 'C'] Heikkinen, Miss. Laina [3, 1, 3, 'female', 26.0, 0, 0, 'STON/O2. 3101282', 7.925, nan, 'S'] Futrelle, Mrs. Jacques Heath (Lily May Peel) [4, 1, 1, 'female', 35.0, 1, 0, '113803', 53.1, 'C123', 'S'] Allen, Mr. William Henry [5, 0, 3, 'male', 35.0, 0, 0, '373450', 8.05, nan, 'S'] for index,row in sample . iteritems(): print (index,row[ 0 ],row[ 1 ],row[ 2 ]) PassengerId 1 2 3 Survived 0 1 1 Pclass 3 1 3 Sex male female female Age 22.0 38.0 26.0 SibSp 1 1 0 Parch 0 0 0 Ticket A/5 21171 PC 17599 STON/O2. 3101282 Fare 7.25 71.2833 7.925 Cabin nan C85 nan Embarked S C S","title":"2. Iteration of rows with  iteritems"},{"location":"Indexing/indexing/#3-indexing-data","text":"Source: Using iloc, loc, & ix to select rows and columns in Pandas DataFrames loc and iloc : The iloc indexer for Pandas Dataframe is used for integer-location based indexing / selection by position. The Pandas loc indexer can be used with DataFrames for two different use cases: a.) Selecting rows by label/index b.) Selecting rows with a boolean / conditional lookup sample . iloc[ 0 : 2 ,:] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } PassengerId Survived Pclass Sex Age SibSp Parch Ticket Fare Cabin Embarked Name Braund, Mr. Owen Harris 1 0 3 male 22.0 1 0 A/5 21171 7.2500 NaN S Cumings, Mrs. John Bradley (Florence Briggs Thayer) 2 1 1 female 38.0 1 0 PC 17599 71.2833 C85 C sample . iloc[ 1 , 0 : 3 ] PassengerId 2 Survived 1 Pclass 1 Name: Cumings, Mrs. John Bradley (Florence Briggs Thayer), dtype: object sample . loc[:, 'Survived' : 'Ticket' ] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Survived Pclass Sex Age SibSp Parch Ticket Name Braund, Mr. Owen Harris 0 3 male 22.0 1 0 A/5 21171 Cumings, Mrs. John Bradley (Florence Briggs Thayer) 1 1 female 38.0 1 0 PC 17599 Heikkinen, Miss. Laina 1 3 female 26.0 0 0 STON/O2. 3101282 Futrelle, Mrs. Jacques Heath (Lily May Peel) 1 1 female 35.0 1 0 113803 Allen, Mr. William Henry 0 3 male 35.0 0 0 373450 sample . loc[ 'Braund, Mr. Owen Harris' ,:] PassengerId 1 Survived 0 Pclass 3 Sex male Age 22 SibSp 1 Parch 0 Ticket A/5 21171 Fare 7.25 Cabin NaN Embarked S Name: Braund, Mr. Owen Harris, dtype: object","title":"3.  Indexing Data"},{"location":"Indexing/indexing/#4-data-filters","text":"Data Filters can be performed by either selecting specific set of column names or by seting boolean filters . Dictionary to DataFrame data = { 'country' : [ 'Belgium' , 'France' , 'Germany' , 'Netherlands' , 'United Kingdom' ], 'population' : [ 11.3 , 64.3 , 81.3 , 16.9 , 64.9 ], 'area' : [ 30510 , 671308 , 357050 , 41526 , 244820 ], 'capital' : [ 'Brussels' , 'Paris' , 'Berlin' , 'Amsterdam' , 'London' ]} countries = pd . DataFrame(data) countries .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } country population area capital 0 Belgium 11.3 30510 Brussels 1 France 64.3 671308 Paris 2 Germany 81.3 357050 Berlin 3 Netherlands 16.9 41526 Amsterdam 4 United Kingdom 64.9 244820 London To set the country as index: countries = countries . set_index( 'country' ) countries .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } population area capital country Belgium 11.3 30510 Brussels France 64.3 671308 Paris Germany 81.3 357050 Berlin Netherlands 16.9 41526 Amsterdam United Kingdom 64.9 244820 London To find the area of each country: countries[ 'area' ] country Belgium 30510 France 671308 Germany 357050 Netherlands 41526 United Kingdom 244820 Name: area, dtype: int64 To create a list instead of pandas Series object. Area = list (countries[ 'area' ]) Area [30510, 671308, 357050, 41526, 244820] To create a sub-DataFrame by choosing area and population countries[[ 'area' , 'population' ]] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } area population country Belgium 30510 11.3 France 671308 64.3 Germany 357050 81.3 Netherlands 41526 16.9 United Kingdom 244820 64.9 To observe slice of data by index names. countries[ 'France' : 'Netherlands' ] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } population area capital country France 64.3 671308 Paris Germany 81.3 357050 Berlin Netherlands 16.9 41526 Amsterdam To observe the data at specific row identified by index name(s) and spefic column identified by column name(s): countries . loc[ 'Germany' , 'area' ] 357050 countries . loc[ 'France' : 'Germany' , [ 'area' , 'population' ]] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } area population country France 671308 64.3 Germany 357050 81.3 To set boolean selection for subDataFrame : countries[ 'area' ] > 100000 country Belgium False France True Germany True Netherlands False United Kingdom True Name: area, dtype: bool countries[countries[ 'area' ] > 100000 ] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } population area capital country France 64.3 671308 Paris Germany 81.3 357050 Berlin United Kingdom 64.9 244820 London","title":"4 - Data Filters:"},{"location":"Indexing/indexing/#5-exercises","text":"EXERCISE : Add a column `density` with the population density (note: population column is expressed in millions) countries[ 'density' ] = countries[ 'population' ] * 1000000 / countries[ 'area' ] countries .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } population area capital density country Belgium 11.3 30510 Brussels 370.370370 France 64.3 671308 Paris 95.783158 Germany 81.3 357050 Berlin 227.699202 Netherlands 16.9 41526 Amsterdam 406.973944 United Kingdom 64.9 244820 London 265.092721 EXERCISE : Select the capital and the population column of those countries where the density is larger than 300 countries . loc[countries[ 'density' ] > 300 , [ 'capital' , 'population' ]] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } capital population country Belgium Brussels 11.3 Netherlands Amsterdam 16.9 EXERCISE : Add a column 'density_ratio' with the ratio of the density to the mean density countries[ 'density_ratio' ] = countries[ 'density' ] / countries[ 'density' ] . mean() countries .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } population area capital density density_ratio country Belgium 11.3 30510 Brussels 370.370370 1.355755 France 64.3 671308 Paris 95.783158 0.350618 Germany 81.3 357050 Berlin 227.699202 0.833502 Netherlands 16.9 41526 Amsterdam 406.973944 1.489744 United Kingdom 64.9 244820 London 265.092721 0.970382 EXERCISE : Change the capital of the UK to Cambridge countries . loc[ 'United Kingdom' , 'capital' ] = 'Cambridge' countries .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } population area capital density density_ratio country Belgium 11.3 30510 Brussels 370.370370 1.355755 France 64.3 671308 Paris 95.783158 0.350618 Germany 81.3 357050 Berlin 227.699202 0.833502 Netherlands 16.9 41526 Amsterdam 406.973944 1.489744 United Kingdom 64.9 244820 Cambridge 265.092721 0.970382 EXERCISE : Select all countries whose population density is between 100 and 300 people/km\u00b2 countries[(countries[ 'density' ] > 100 ) & (countries[ 'density' ] < 300 )] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } population area capital density density_ratio country Germany 81.3 357050 Berlin 227.699202 0.833502 United Kingdom 64.9 244820 Cambridge 265.092721 0.970382","title":"5. Exercises:"},{"location":"Indexing/indexing/#references","text":"Pydata documentation: Group by: split-apply-combine EuroScipy 2016 Pandas Tutorial by Joris Van den Bossche and Nicholas Devenish","title":"References:"},{"location":"Join/join/","text":"Data Operation: concat(), merge(), join() This notebook will provide a walkthrough for data concat, merge and join functionality for combining multiple DataFrame objects. Some part of this notebook are taken from Pydata tutorials. Read more about these functionality from Pandas Pydata Document about concat, merge, join [1]. import pandas as pd import numpy as np import seaborn as sns import matplotlib.pyplot as plt % matplotlib inline sns . set() 1. Concatanation of data frames by index: Here we create three seperate Dataframe with same column names (e.g., col A, col B, col C, col D ) and create a final dataframe with concatenating these dataframes. Read more from pydata The defult setting is: pd.concat(objs, axis=0, join='outer', ignore_index=False, keys=None, levels=None, names=None, verify_integrity=False, copy=True) Image courtesy : Pydata df1 = pd . DataFrame({ 'col A' : [ 'A0' , 'A1' , 'A2' , 'A3' ], 'col B' : [ 'B0' , 'B1' , 'B2' , 'B3' ], 'col C' : [ 'C0' , 'C1' , 'C2' , 'C3' ], 'col D' : [ 'D0' , 'D1' , 'D2' , 'D3' ]}, index = [ 0 , 1 , 2 , 3 ]) df2 = pd . DataFrame({ 'col A' : [ 'A4' , 'A5' , 'A6' , 'A7' ], 'col B' : [ 'B4' , 'B5' , 'B6' , 'B7' ], 'col C' : [ 'C4' , 'C5' , 'C6' , 'C7' ], 'col D' : [ 'D4' , 'D5' , 'D6' , 'D7' ]}, index = [ 4 , 5 , 6 , 7 ]) df3 = pd . DataFrame({ 'col A' : [ 'A8' , 'A9' , 'A10' , 'A11' ], 'col B' : [ 'B8' , 'B9' , 'B10' , 'B11' ], 'col C' : [ 'C8' , 'C9' , 'C10' , 'C11' ], 'col D' : [ 'D8' , 'D9' , 'D10' , 'D11' ]}, index = [ 8 , 9 , 10 , 11 ]) frames = [df1, df2, df3] result = pd . concat(frames, sort = False ) result .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } col A col B col C col D 0 A0 B0 C0 D0 1 A1 B1 C1 D1 2 A2 B2 C2 D2 3 A3 B3 C3 D3 4 A4 B4 C4 D4 5 A5 B5 C5 D5 6 A6 B6 C6 D6 7 A7 B7 C7 D7 8 A8 B8 C8 D8 9 A9 B9 C9 D9 10 A10 B10 C10 D10 11 A11 B11 C11 D11 Concatenating different dataframes with different column names with defult join=\"outer\" . df4 = pd . DataFrame({ 'colE' : [ 'E4' , 'E5' , 'E6' , 'E7' ], 'colF' : [ 'F4' , 'F5' , 'F6' , 'F7' ], 'colG' : [ 'G4' , 'G5' , 'G6' , 'G7' ], 'colH' : [ 'H4' , 'H5' , 'H6' , 'H7' ]}, index = [ 4 , 5 , 6 , 7 ]) df5 = pd . DataFrame({ 'colA' : [ 'A8' , 'A9' , 'A10' , 'A11' ], 'colE' : [ 'E8' , 'E9' , 'E10' , 'E11' ], 'colC' : [ 'C8' , 'C9' , 'C10' , 'C11' ], 'colH' : [ 'H8' , 'H9' , 'H10' , 'H11' ]}, index = [ 8 , 9 , 10 , 11 ]) frames = [df1, df2, df3] result = pd . concat(frames, sort = False ) result .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } colA colB colC colD colE colF colG colH 0 A0 B0 C0 D0 NaN NaN NaN NaN 1 A1 B1 C1 D1 NaN NaN NaN NaN 2 A2 B2 C2 D2 NaN NaN NaN NaN 3 A3 B3 C3 D3 NaN NaN NaN NaN 4 NaN NaN NaN NaN E4 F4 G4 H4 5 NaN NaN NaN NaN E5 F5 G5 H5 6 NaN NaN NaN NaN E6 F6 G6 H6 7 NaN NaN NaN NaN E7 F7 G7 H7 8 A8 NaN C8 NaN E8 NaN NaN H8 9 A9 NaN C9 NaN E9 NaN NaN H9 10 A10 NaN C10 NaN E10 NaN NaN H10 11 A11 NaN C11 NaN E11 NaN NaN H11 Concatenating different dataframes with different column names with defult join=\"inner\" and axis =0 . frames = [df1, df5] result = pd . concat(frames, sort = False , join = \"inner\" ) result .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } colA colC 0 A0 C0 1 A1 C1 2 A2 C2 3 A3 C3 8 A8 C8 9 A9 C9 10 A10 C10 11 A11 C11 axis = 1 axis = 0 Image Courtesy www.towardsdatascience.com 2. Merge dataframe Two DataFrame object can be merged on specific key . Defult setting : pd.merge(left, right, how='inner', on=None, left_on=None, right_on=None, left_index=False, right_index=False, sort=True, suffixes=('_x', '_y'), copy=True, indicator=False, validate=None) Image courtesy : Pydata left = pd . DataFrame({ 'key' : [ 'K0' , 'K1' , 'K2' , 'K3' ], 'A' : [ 'A0' , 'A1' , 'A2' , 'A3' ], 'B' : [ 'B0' , 'B1' , 'B2' , 'B3' ]}) right = pd . DataFrame({ 'key' : [ 'K0' , 'K1' , 'K2' , 'K3' ], 'C' : [ 'C0' , 'C1' , 'C2' , 'C3' ], 'D' : [ 'D0' , 'D1' , 'D2' , 'D3' ]}) result = pd . merge(left, right, on = 'key' ) result .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } key A B C D 0 K0 A0 B0 C0 D0 1 K1 A1 B1 C1 D1 2 K2 A2 B2 C2 D2 3 K3 A3 B3 C3 D3 Image Courtesy www.datascience.quantecon.org 3. Join DataFrame Joining two DataFrame objects with join operation. Defult setting is join='inner' . ![img]( Image courtesy : Pydata left = pd . DataFrame({ 'A' : [ 'A0' , 'A1' , 'A2' ], 'B' : [ 'B0' , 'B1' , 'B2' ]}, index = [ 'K0' , 'K1' , 'K2' ]) right = pd . DataFrame({ 'C' : [ 'C0' , 'C2' , 'C3' ], 'D' : [ 'D0' , 'D2' , 'D3' ]}, index = [ 'K0' , 'K2' , 'K3' ]) result = left . join(right) result .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } A B C D K0 A0 B0 C0 D0 K1 A1 B1 NaN NaN K2 A2 B2 C2 D2 Image Courtesy www.towardsdatascience.com References: Pandas Pydata Document Python Pandas DataFrame Join, Merge, and Concatenate Merge, concat, Join in pandas","title":"Concat, Merge and Join"},{"location":"Join/join/#data-operation-concat-merge-join","text":"This notebook will provide a walkthrough for data concat, merge and join functionality for combining multiple DataFrame objects. Some part of this notebook are taken from Pydata tutorials. Read more about these functionality from Pandas Pydata Document about concat, merge, join [1]. import pandas as pd import numpy as np import seaborn as sns import matplotlib.pyplot as plt % matplotlib inline sns . set()","title":"Data Operation: concat(), merge(), join()"},{"location":"Join/join/#1-concatanation-of-data-frames-by-index","text":"Here we create three seperate Dataframe with same column names (e.g., col A, col B, col C, col D ) and create a final dataframe with concatenating these dataframes. Read more from pydata The defult setting is: pd.concat(objs, axis=0, join='outer', ignore_index=False, keys=None, levels=None, names=None, verify_integrity=False, copy=True) Image courtesy : Pydata df1 = pd . DataFrame({ 'col A' : [ 'A0' , 'A1' , 'A2' , 'A3' ], 'col B' : [ 'B0' , 'B1' , 'B2' , 'B3' ], 'col C' : [ 'C0' , 'C1' , 'C2' , 'C3' ], 'col D' : [ 'D0' , 'D1' , 'D2' , 'D3' ]}, index = [ 0 , 1 , 2 , 3 ]) df2 = pd . DataFrame({ 'col A' : [ 'A4' , 'A5' , 'A6' , 'A7' ], 'col B' : [ 'B4' , 'B5' , 'B6' , 'B7' ], 'col C' : [ 'C4' , 'C5' , 'C6' , 'C7' ], 'col D' : [ 'D4' , 'D5' , 'D6' , 'D7' ]}, index = [ 4 , 5 , 6 , 7 ]) df3 = pd . DataFrame({ 'col A' : [ 'A8' , 'A9' , 'A10' , 'A11' ], 'col B' : [ 'B8' , 'B9' , 'B10' , 'B11' ], 'col C' : [ 'C8' , 'C9' , 'C10' , 'C11' ], 'col D' : [ 'D8' , 'D9' , 'D10' , 'D11' ]}, index = [ 8 , 9 , 10 , 11 ]) frames = [df1, df2, df3] result = pd . concat(frames, sort = False ) result .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } col A col B col C col D 0 A0 B0 C0 D0 1 A1 B1 C1 D1 2 A2 B2 C2 D2 3 A3 B3 C3 D3 4 A4 B4 C4 D4 5 A5 B5 C5 D5 6 A6 B6 C6 D6 7 A7 B7 C7 D7 8 A8 B8 C8 D8 9 A9 B9 C9 D9 10 A10 B10 C10 D10 11 A11 B11 C11 D11 Concatenating different dataframes with different column names with defult join=\"outer\" . df4 = pd . DataFrame({ 'colE' : [ 'E4' , 'E5' , 'E6' , 'E7' ], 'colF' : [ 'F4' , 'F5' , 'F6' , 'F7' ], 'colG' : [ 'G4' , 'G5' , 'G6' , 'G7' ], 'colH' : [ 'H4' , 'H5' , 'H6' , 'H7' ]}, index = [ 4 , 5 , 6 , 7 ]) df5 = pd . DataFrame({ 'colA' : [ 'A8' , 'A9' , 'A10' , 'A11' ], 'colE' : [ 'E8' , 'E9' , 'E10' , 'E11' ], 'colC' : [ 'C8' , 'C9' , 'C10' , 'C11' ], 'colH' : [ 'H8' , 'H9' , 'H10' , 'H11' ]}, index = [ 8 , 9 , 10 , 11 ]) frames = [df1, df2, df3] result = pd . concat(frames, sort = False ) result .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } colA colB colC colD colE colF colG colH 0 A0 B0 C0 D0 NaN NaN NaN NaN 1 A1 B1 C1 D1 NaN NaN NaN NaN 2 A2 B2 C2 D2 NaN NaN NaN NaN 3 A3 B3 C3 D3 NaN NaN NaN NaN 4 NaN NaN NaN NaN E4 F4 G4 H4 5 NaN NaN NaN NaN E5 F5 G5 H5 6 NaN NaN NaN NaN E6 F6 G6 H6 7 NaN NaN NaN NaN E7 F7 G7 H7 8 A8 NaN C8 NaN E8 NaN NaN H8 9 A9 NaN C9 NaN E9 NaN NaN H9 10 A10 NaN C10 NaN E10 NaN NaN H10 11 A11 NaN C11 NaN E11 NaN NaN H11 Concatenating different dataframes with different column names with defult join=\"inner\" and axis =0 . frames = [df1, df5] result = pd . concat(frames, sort = False , join = \"inner\" ) result .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } colA colC 0 A0 C0 1 A1 C1 2 A2 C2 3 A3 C3 8 A8 C8 9 A9 C9 10 A10 C10 11 A11 C11 axis = 1 axis = 0 Image Courtesy www.towardsdatascience.com","title":"1. Concatanation of data frames by index:"},{"location":"Join/join/#2-merge-dataframe","text":"Two DataFrame object can be merged on specific key . Defult setting : pd.merge(left, right, how='inner', on=None, left_on=None, right_on=None, left_index=False, right_index=False, sort=True, suffixes=('_x', '_y'), copy=True, indicator=False, validate=None) Image courtesy : Pydata left = pd . DataFrame({ 'key' : [ 'K0' , 'K1' , 'K2' , 'K3' ], 'A' : [ 'A0' , 'A1' , 'A2' , 'A3' ], 'B' : [ 'B0' , 'B1' , 'B2' , 'B3' ]}) right = pd . DataFrame({ 'key' : [ 'K0' , 'K1' , 'K2' , 'K3' ], 'C' : [ 'C0' , 'C1' , 'C2' , 'C3' ], 'D' : [ 'D0' , 'D1' , 'D2' , 'D3' ]}) result = pd . merge(left, right, on = 'key' ) result .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } key A B C D 0 K0 A0 B0 C0 D0 1 K1 A1 B1 C1 D1 2 K2 A2 B2 C2 D2 3 K3 A3 B3 C3 D3 Image Courtesy www.datascience.quantecon.org","title":"2. Merge dataframe"},{"location":"Join/join/#3-join-dataframe","text":"Joining two DataFrame objects with join operation. Defult setting is join='inner' . ![img]( Image courtesy : Pydata left = pd . DataFrame({ 'A' : [ 'A0' , 'A1' , 'A2' ], 'B' : [ 'B0' , 'B1' , 'B2' ]}, index = [ 'K0' , 'K1' , 'K2' ]) right = pd . DataFrame({ 'C' : [ 'C0' , 'C2' , 'C3' ], 'D' : [ 'D0' , 'D2' , 'D3' ]}, index = [ 'K0' , 'K2' , 'K3' ]) result = left . join(right) result .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } A B C D K0 A0 B0 C0 D0 K1 A1 B1 NaN NaN K2 A2 B2 C2 D2 Image Courtesy www.towardsdatascience.com","title":"3. Join DataFrame"},{"location":"Join/join/#references","text":"Pandas Pydata Document Python Pandas DataFrame Join, Merge, and Concatenate Merge, concat, Join in pandas","title":"References:"},{"location":"Lambda/lambda/","text":"Apply and Lambda Transformation In this notebook we will learn to perform the column data operation through implementation of apply() and lambda functionality. import pandas as pd import numpy as np import seaborn as sns import matplotlib.pyplot as plt % matplotlib inline Load data titanic = pd . read_csv( 'data/titanic.csv' ) df1 = titanic . set_index( 'Name' ) df1 . head( 2 ) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } PassengerId Survived Pclass Sex Age SibSp Parch Ticket Fare Cabin Embarked Name Braund, Mr. Owen Harris 1 0 3 male 22.0 1 0 A/5 21171 7.2500 NaN S Cumings, Mrs. John Bradley (Florence Briggs Thayer) 2 1 1 female 38.0 1 0 PC 17599 71.2833 C85 C 1. Implementation of Apply () with lambda() function Apply lambda functionality to age column. df1[ 'remaining-age' ] = df1[ 'Age' ] . apply( lambda x: 100 - x) . head( 5 ) df1 . head( 5 ) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } PassengerId Survived Pclass Sex Age SibSp Parch Ticket Fare Cabin Embarked remaining-age Name Braund, Mr. Owen Harris 1 0 3 male 22.0 1 0 A/5 21171 7.2500 NaN S 78.0 Cumings, Mrs. John Bradley (Florence Briggs Thayer) 2 1 1 female 38.0 1 0 PC 17599 71.2833 C85 C 62.0 Heikkinen, Miss. Laina 3 1 3 female 26.0 0 0 STON/O2. 3101282 7.9250 NaN S 74.0 Futrelle, Mrs. Jacques Heath (Lily May Peel) 4 1 1 female 35.0 1 0 113803 53.1000 C123 S 65.0 Allen, Mr. William Henry 5 0 3 male 35.0 0 0 373450 8.0500 NaN S 65.0 Apply lambda functionality to Fare column to transform it to new value. df1[ 'Fare' ] . apply( lambda x: ( 10 * x ** 2 + 2 * x + 4 ) / 10 ) . head( 5 ) Name Braund, Mr. Owen Harris 54.412500 Cumings, Mrs. John Bradley (Florence Briggs Thayer) 5095.965519 Heikkinen, Miss. Laina 64.790625 Futrelle, Mrs. Jacques Heath (Lily May Peel) 2830.630000 Allen, Mr. William Henry 66.812500 Name: Fare, dtype: float64 Let us write a new function to supply inside the apply() function. def newfeature (x): return 10 + x / 3 + x ** 2 df1[ 'Fare' ] . apply(newfeature) . head( 4 ) Name Braund, Mr. Owen Harris 64.979167 Cumings, Mrs. John Bradley (Florence Briggs Thayer) 5115.069959 Heikkinen, Miss. Laina 75.447292 Futrelle, Mrs. Jacques Heath (Lily May Peel) 2847.310000 Name: Fare, dtype: float64 2. Column Operation with Lambda function Lets create a new random dataframe to play around. dates = pd . date_range( '1/1/2000' , periods = 100 ) df = pd . DataFrame(np . random . randn( 100 , 4 ), index = dates, columns = [ 'A' , 'B' , 'C' , 'D' ]) df . head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } A B C D 2000-01-01 -0.656738 -0.461095 -0.259647 0.890244 2000-01-02 0.652611 0.906148 -0.527606 -0.106089 2000-01-03 -0.067463 1.407429 1.414694 -1.266369 2000-01-04 0.301058 0.624163 -0.144190 -1.177690 2000-01-05 1.557796 -1.497422 0.545636 -1.006319 We can directly add, multiply, substract etc among columns if they have same data types. df[ 'E' ] = (df[ 'A' ] + df[ 'B' ]) / df[ 'C' ] df . head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } A B C D E 2000-01-01 -0.656738 -0.461095 -0.259647 0.890244 4.305207 2000-01-02 0.652611 0.906148 -0.527606 -0.106089 -2.954399 2000-01-03 -0.067463 1.407429 1.414694 -1.266369 0.947177 2000-01-04 0.301058 0.624163 -0.144190 -1.177690 -6.416660 2000-01-05 1.557796 -1.497422 0.545636 -1.006319 0.110649 One can use lambda functions to transform the columns before the column operation. df[ 'F' ] = df[ 'A' ] . apply( lambda x : 10 + x) + df[ 'E' ] . apply( lambda x: x + 20 if x > 0 else x) df . head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } A B C D E F 2000-01-01 -0.656738 -0.461095 -0.259647 0.890244 4.305207 33.648469 2000-01-02 0.652611 0.906148 -0.527606 -0.106089 -2.954399 7.698212 2000-01-03 -0.067463 1.407429 1.414694 -1.266369 0.947177 30.879714 2000-01-04 0.301058 0.624163 -0.144190 -1.177690 -6.416660 3.884397 2000-01-05 1.557796 -1.497422 0.545636 -1.006319 0.110649 31.668445 References: Pydata document for Pandas","title":"Apply and Lambda Transform"},{"location":"Lambda/lambda/#apply-and-lambda-transformation","text":"In this notebook we will learn to perform the column data operation through implementation of apply() and lambda functionality. import pandas as pd import numpy as np import seaborn as sns import matplotlib.pyplot as plt % matplotlib inline","title":"Apply and Lambda Transformation"},{"location":"Lambda/lambda/#load-data","text":"titanic = pd . read_csv( 'data/titanic.csv' ) df1 = titanic . set_index( 'Name' ) df1 . head( 2 ) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } PassengerId Survived Pclass Sex Age SibSp Parch Ticket Fare Cabin Embarked Name Braund, Mr. Owen Harris 1 0 3 male 22.0 1 0 A/5 21171 7.2500 NaN S Cumings, Mrs. John Bradley (Florence Briggs Thayer) 2 1 1 female 38.0 1 0 PC 17599 71.2833 C85 C","title":"Load data"},{"location":"Lambda/lambda/#1-implementation-of-apply-with-lambda-function","text":"Apply lambda functionality to age column. df1[ 'remaining-age' ] = df1[ 'Age' ] . apply( lambda x: 100 - x) . head( 5 ) df1 . head( 5 ) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } PassengerId Survived Pclass Sex Age SibSp Parch Ticket Fare Cabin Embarked remaining-age Name Braund, Mr. Owen Harris 1 0 3 male 22.0 1 0 A/5 21171 7.2500 NaN S 78.0 Cumings, Mrs. John Bradley (Florence Briggs Thayer) 2 1 1 female 38.0 1 0 PC 17599 71.2833 C85 C 62.0 Heikkinen, Miss. Laina 3 1 3 female 26.0 0 0 STON/O2. 3101282 7.9250 NaN S 74.0 Futrelle, Mrs. Jacques Heath (Lily May Peel) 4 1 1 female 35.0 1 0 113803 53.1000 C123 S 65.0 Allen, Mr. William Henry 5 0 3 male 35.0 0 0 373450 8.0500 NaN S 65.0 Apply lambda functionality to Fare column to transform it to new value. df1[ 'Fare' ] . apply( lambda x: ( 10 * x ** 2 + 2 * x + 4 ) / 10 ) . head( 5 ) Name Braund, Mr. Owen Harris 54.412500 Cumings, Mrs. John Bradley (Florence Briggs Thayer) 5095.965519 Heikkinen, Miss. Laina 64.790625 Futrelle, Mrs. Jacques Heath (Lily May Peel) 2830.630000 Allen, Mr. William Henry 66.812500 Name: Fare, dtype: float64 Let us write a new function to supply inside the apply() function. def newfeature (x): return 10 + x / 3 + x ** 2 df1[ 'Fare' ] . apply(newfeature) . head( 4 ) Name Braund, Mr. Owen Harris 64.979167 Cumings, Mrs. John Bradley (Florence Briggs Thayer) 5115.069959 Heikkinen, Miss. Laina 75.447292 Futrelle, Mrs. Jacques Heath (Lily May Peel) 2847.310000 Name: Fare, dtype: float64","title":"1. Implementation of Apply () with lambda() function"},{"location":"Lambda/lambda/#2-column-operation-with-lambda-function","text":"Lets create a new random dataframe to play around. dates = pd . date_range( '1/1/2000' , periods = 100 ) df = pd . DataFrame(np . random . randn( 100 , 4 ), index = dates, columns = [ 'A' , 'B' , 'C' , 'D' ]) df . head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } A B C D 2000-01-01 -0.656738 -0.461095 -0.259647 0.890244 2000-01-02 0.652611 0.906148 -0.527606 -0.106089 2000-01-03 -0.067463 1.407429 1.414694 -1.266369 2000-01-04 0.301058 0.624163 -0.144190 -1.177690 2000-01-05 1.557796 -1.497422 0.545636 -1.006319 We can directly add, multiply, substract etc among columns if they have same data types. df[ 'E' ] = (df[ 'A' ] + df[ 'B' ]) / df[ 'C' ] df . head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } A B C D E 2000-01-01 -0.656738 -0.461095 -0.259647 0.890244 4.305207 2000-01-02 0.652611 0.906148 -0.527606 -0.106089 -2.954399 2000-01-03 -0.067463 1.407429 1.414694 -1.266369 0.947177 2000-01-04 0.301058 0.624163 -0.144190 -1.177690 -6.416660 2000-01-05 1.557796 -1.497422 0.545636 -1.006319 0.110649 One can use lambda functions to transform the columns before the column operation. df[ 'F' ] = df[ 'A' ] . apply( lambda x : 10 + x) + df[ 'E' ] . apply( lambda x: x + 20 if x > 0 else x) df . head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } A B C D E F 2000-01-01 -0.656738 -0.461095 -0.259647 0.890244 4.305207 33.648469 2000-01-02 0.652611 0.906148 -0.527606 -0.106089 -2.954399 7.698212 2000-01-03 -0.067463 1.407429 1.414694 -1.266369 0.947177 30.879714 2000-01-04 0.301058 0.624163 -0.144190 -1.177690 -6.416660 3.884397 2000-01-05 1.557796 -1.497422 0.545636 -1.006319 0.110649 31.668445","title":"2. Column Operation with Lambda function"},{"location":"Lambda/lambda/#references","text":"Pydata document for Pandas","title":"References:"},{"location":"Visualization/visual/","text":"DataFrame Preliminaries in Pandas In this norebook ww will create some data visualization by implementing Pandas plot and other functions. import pandas as pd import numpy as np import random as random import seaborn as sns import matplotlib.pyplot as plt % matplotlib inline sns . set() To create new data frame from list of dictionaries and visualize them. Here we will create first a list with collection of dictionaries. Each of the dictionary will have keys and values. Using this list of dictionaries, we will create another dataframe. The keys of the dictionary will serve as the column names. LD = [] letter = [ 'A' , 'B' , 'C' , 'D' , 'E' , 'F' , 'G' , 'H' , 'X' ] for i in range ( 100 ): LD . append({ 'Player' : random . choice(letter) + \\ random . choice(letter) + \\ random . choice(letter) + \\ random . choice(letter),\\ 'game1' : random . uniform( 0 , 1 ),\\ 'game2' : random . uniform( 0 , 1 ),\\ 'game3' : random . uniform( 0 , 1 ), 'game4' : random . uniform( 0 , 1 ), 'game5' : random . uniform( 0 , 1 )}) DF = pd . DataFrame(LD) DF = DF . set_index( \"Player\" ) DF . head( 3 ) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } game1 game2 game3 game4 game5 Player HFDD 0.481069 0.474633 0.689590 0.395129 0.242217 AXXG 0.676598 0.959418 0.460717 0.513393 0.058434 BHAB 0.215308 0.086760 0.080839 0.818904 0.953768 Data Visualization with Pandas Individual columns of data can be visualized as line plot DF . plot(figsize = [ 15 , 4 ]) <matplotlib.axes._subplots.AxesSubplot at 0x26c35149d30> Abar plot can be created with plot.barh for horizontal bar with extra setting stacked=True for adding contribution from each column data. DF[ 0 : 20 ] . plot . barh(stacked = True ,figsize = ( 15 , 8 ),fontsize = 10 ) <matplotlib.axes._subplots.AxesSubplot at 0x26c36740278> Verticle bar can be created with plot.bar() functionality with stacked=False setting. DF[ 0 : 10 ] . plot . bar(stacked = False ,figsize = ( 15 , 4 ),fontsize = 10 ) <matplotlib.axes._subplots.AxesSubplot at 0x26c37193a58> pandas plotting provides scatter_matrix functions to plot col by col scater plot with kernel density estimation- kde . from pandas.plotting import scatter_matrix scatter_matrix(DF, alpha = 0.2 , figsize = ( 10 , 8 ), diagonal = 'kde' ) plt . show() Pandas plotting also has plot.hexbin() functionality for beautiful scatter plot. DF . plot . hexbin(x = 'game1' , y = 'game2' ,figsize = ( 8 , 6 ), gridsize = 25 ) <matplotlib.axes._subplots.AxesSubplot at 0x26c39cba128> Reference: Pydata visualization documentation","title":"Data Visualization"},{"location":"Visualization/visual/#dataframe-preliminaries-in-pandas","text":"In this norebook ww will create some data visualization by implementing Pandas plot and other functions. import pandas as pd import numpy as np import random as random import seaborn as sns import matplotlib.pyplot as plt % matplotlib inline sns . set()","title":"DataFrame Preliminaries in Pandas"},{"location":"Visualization/visual/#to-create-new-data-frame-from-list-of-dictionaries-and-visualize-them","text":"Here we will create first a list with collection of dictionaries. Each of the dictionary will have keys and values. Using this list of dictionaries, we will create another dataframe. The keys of the dictionary will serve as the column names. LD = [] letter = [ 'A' , 'B' , 'C' , 'D' , 'E' , 'F' , 'G' , 'H' , 'X' ] for i in range ( 100 ): LD . append({ 'Player' : random . choice(letter) + \\ random . choice(letter) + \\ random . choice(letter) + \\ random . choice(letter),\\ 'game1' : random . uniform( 0 , 1 ),\\ 'game2' : random . uniform( 0 , 1 ),\\ 'game3' : random . uniform( 0 , 1 ), 'game4' : random . uniform( 0 , 1 ), 'game5' : random . uniform( 0 , 1 )}) DF = pd . DataFrame(LD) DF = DF . set_index( \"Player\" ) DF . head( 3 ) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } game1 game2 game3 game4 game5 Player HFDD 0.481069 0.474633 0.689590 0.395129 0.242217 AXXG 0.676598 0.959418 0.460717 0.513393 0.058434 BHAB 0.215308 0.086760 0.080839 0.818904 0.953768","title":"To create new  data frame from  list of dictionaries and visualize them."},{"location":"Visualization/visual/#data-visualization-with-pandas","text":"Individual columns of data can be visualized as line plot DF . plot(figsize = [ 15 , 4 ]) <matplotlib.axes._subplots.AxesSubplot at 0x26c35149d30> Abar plot can be created with plot.barh for horizontal bar with extra setting stacked=True for adding contribution from each column data. DF[ 0 : 20 ] . plot . barh(stacked = True ,figsize = ( 15 , 8 ),fontsize = 10 ) <matplotlib.axes._subplots.AxesSubplot at 0x26c36740278> Verticle bar can be created with plot.bar() functionality with stacked=False setting. DF[ 0 : 10 ] . plot . bar(stacked = False ,figsize = ( 15 , 4 ),fontsize = 10 ) <matplotlib.axes._subplots.AxesSubplot at 0x26c37193a58> pandas plotting provides scatter_matrix functions to plot col by col scater plot with kernel density estimation- kde . from pandas.plotting import scatter_matrix scatter_matrix(DF, alpha = 0.2 , figsize = ( 10 , 8 ), diagonal = 'kde' ) plt . show() Pandas plotting also has plot.hexbin() functionality for beautiful scatter plot. DF . plot . hexbin(x = 'game1' , y = 'game2' ,figsize = ( 8 , 6 ), gridsize = 25 ) <matplotlib.axes._subplots.AxesSubplot at 0x26c39cba128>","title":"Data Visualization with Pandas"},{"location":"Visualization/visual/#reference","text":"Pydata visualization documentation","title":"Reference:"}]}